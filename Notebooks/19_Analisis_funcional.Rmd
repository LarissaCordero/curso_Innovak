---
title: "Analisis funcional para bacterias "
output: html_notebook
---

#Introduccion

El analisis funcional de los datos consiste en transformar nuestros datos de taxonomia identificados a grupos que "hacen" cosas en el suelo es decir descubrir sus funciones. Para ello vamos a usar el software METAGENassist que es un pipeline online que se usa para estudios metagenomicos comparativos. Ademas de otras caracterisitcas, este software realiza un mapeo automatico de taxonomia a fenotipo usando casi 20 categorias fenotipicas diferentes usando la informacion fenotipica de especies bacterianas listadas en la base de datos NCBI. De aqui obtienen informacion como metabolismo o fuente de energia basado en taxonomia al nivel de genero.

```{r}
# Libreria

library(phyloseq)
library(pheatmap)
library(RColorBrewer)
library(car)


load("Vid_ejemplos.RData")
```

# Pre procesamiento de datos

Antes que nada tenemos que preparar los datos para subirlo al servidor:

1. Primero que nada tenemos que aglomerar los datos por Genero porque el software no acepta identificacion taxonomica repetida

```{r}
Phyla_fun <- tax_glom(vid_bio, taxrank = "Genus", NArm = FALSE)

# Extraer
OTU_matrix <- as.data.frame(Phyla_fun@otu_table)
Tax_matrix <- as.data.frame(Phyla_fun@tax_table)
metadata <- as.data.frame(Phyla_fun@sam_data)

# invalid object error: no lo lee como tabla por eso lo cambiamos asi 
metadata <- as.matrix(metadata)
metadata <- as.data.frame(metadata)

# Guardar en materiales

write.csv(OTU_matrix,"~/capR/curso/curso_Innovak/Material_clase/vid_otu.csv")

write.csv(Tax_matrix,"~/capR/curso/curso_Innovak/Material_clase/vid_taxa.csv")

write.csv(metadata,"~/capR/curso/curso_Innovak/Material_clase/vid_meta.csv")

```

2. Ahora en excel vamos a unir las tablas en un solo archivo csv en el    que las filas son las muestras y las columnas son los perfiles taxonomicos. Para ello vamos a juntar cada nivel taxonomico en una sola celda separados por punto y coma


Para ello vamos a usar la funcion concatenate (A1,";",B1) en Excel

*el nuestro excel viene la funcion como concatenar y es empezar desde reino , ademas vamos ponienod todas las columnas y al final te las junta en una sola celda, abrir vid_taxa

*luego seleccionamos ctl+c ctl+v y pegar como valor para que quite las formulas 

*ahora vamos a usar la formula de transponer y seleccionamos toda la columna H

*ahora seleccionar toda la fila AH Y COpiar pegar cmoo valores para que se quite la formula de transponer

*ahora abrir vid_otu y vamos a copiar como lo de AH y ponerlo en vid_otu a partir de B1

*copiar de metadata las columnas de tratamiento y suelo y pegarla en vid_otu despues del ID antes de que empiecen las bacterias, y guardar archivo como vid_funcional

*Meternos a metageneassist

2. Ahora en excel vamos a unir las tablas en un solo archivo csv en el que las filas son las muestras y las columnas son los perfiles taxonomicos. Para ello vamos a juntar cada nivel taxonomico en una sola celda separados por punto y coma.

Para ello vamos a usar la funcion concatenate(A1,";",B1) en Excel

# Flujo de trabajo en Metagenassist

1. Subir datos 

Después de subir sus datos, aparece la pantalla de Verificación de integridad de datos. Si hay algún problema con los archivos de entrada, se anotarán aquí. (Nos aparece una leyenda donde dice que minimo son 3 muestras pero si las acepto)
Dejemos tal cual la opcion que aparece y clic en submit para ir a la parte de filtar...

El informe enumera el número de muestras y el número de variables (taxones) en el perfil taxonómico presentado, y puede indicar que algunos taxones se eliminaron porque tenían una abundancia constante en todas las muestras (por ejemplo, todos ceros).

Más abajo en la página se le pedirá que elija si desea combinar OTU con el mismo asignación taxonómica o mantenerlos separados. Eso lo dejamos en DEFAULT.

2. Filtrar datos

A continuación aparece la página de Filtrado de datos. Este es un paso importante para eliminar materiales de baja calidad o datos poco informativos. La primera opción es excluir lecturas no asignadas y no asignadas. Algunos conjuntos de datos puede incluir una etiqueta "no asignado", que puede tener un gran efecto sesgado en ciertas estadísticas pruebas (por ejemplo, PCA). Las tablas de muestra por fenotipo derivadas internamente también incluyen recuentos de lecturas que no se pudo asignar a un fenotipo, que también se puede excluir. La segunda opción es eliminar variables (por ejemplo, taxones) con abundancia cero en un cierto porcentaje de muestras que podrían de lo contrario causará problemas para pruebas como SVM. Finalmente, se utilizan varios métodos de filtrado de datos para eliminar valores muy bajos o valores que son casi constantes en todas las muestras

El unico cambio al default 90% de ceros (quitar aqui la opcion ya que tenemos muy pocas muestras ypara que no nos vaya a eliminar todo) para avitar qye nos quite taxones que solo aparecen en S85

Aparece la página Resultados del filtrado de datos, que ofrece un desglose de las variables (por ejemplo, taxones) que fueron eliminados de los datos. 

Comparamos filtrado IQR y none y no hubo una reduccion extrema de datos por lo que se dejo en IQR



3. Normalizar datos 

Luego llegamos a la página de Normalización de datos. La estructura de datos interna se transforma ahora a una tabla en la que cada fila representa una muestra y cada columna representa una característica (taxón). Con los datos estructurados en este formato, se pueden utilizar dos tipos de protocolos de normalización de datos, por filas. Se puede utilizar la normalización y la normalización por columnas. La normalización por filas tiene como objetivo
normalice cada muestra (fila) para que sean comparables entre sí. En cuanto a columnas La normalización tiene como objetivo hacer que las características (columnas) sean más comparables en magnitud entre sí. La normalización de datos es un paso importante porque muchas pruebas estadísticas comunes suponen
datos distribuidos aproximadamente normalmente, pero este no suele ser el caso con el perfil taxonómico bruto distribuciones.

En "Normalización por filas", seleccione "Normalización por suma". Esto se ajustará según las variaciones secuenciar la cobertura entre muestras normalizando a la misma abundancia total para cada muestra. En "Normalización por columnas", seleccione "Escalado de Pareto" y haga clic en Procesar. botón en la parte inferior de la página.

Como resultado, se muestran las curvas de densidad antes y después de la normalización para los principales datos taxonómicos.
en la página siguiente.

_nota: Los graficos de normalizacion toman una eleccion al azar_ 



4. Elegir tests estadisticos

Después del procesamiento inicial de datos, se muestra una lista de pruebas estadísticas disponibles. También puedes seleccionar
los diferentes análisis de la barra lateral.

Sin embargo, dependiendo de nuestras variables es que se podran elegir los tests. En este caso elegiremos T test y veremos si se el software nos lo permite

5. Explorando resultados

El software procesa nuestras muestras y dentro de la pagina podemos visualizar muchos graficos que se hicieron con los datos

correlacion- si estan en rojo los dos aumentan o disminuyen y los mas azules estaran afectados por separado si uno aumneta el otro disminuye 

dendograma- que tan relacionadas estan nuestras muesras 

6. Descargar los datos 

Click en el enlace "Descargar" . “Descargar”. zip” que incluye todos los datos procesados e imágenes que vimos. Un archivo readme en el paquete de descarga describe los distintos atascos de tráfico. Los datos permanecerán en el servidor durante 72 horas antes de ser eliminados automáticamente.

# Checando los datos descargados

Nuestro archivo zip contiene todas las imagenes que generamos dentro del software asi como las tablas con las cuales se generaron esas imagenes. Si bien los graficos que genera el software estan medianamente decentes (y ustedes podrian presentarlos si no tienen tiempo) siempre hay posibilidad de mejorarlos en R. Ademas muchos de los datos se pueden presentar de otras maneras por lo que lo que vamos a ocupar de aqui son las tablas que nos arroja el software.

Si se fijan el software nos categorizo de muchas maneras nuestros datos desde patogenicidad, esporulacion hasta tipo de metabolismo. Dado que ahorita nuestro enfoque es en suelo, el grupo funcional mas importante que pueden reportar es tipo de metabolismo seguido de fuente de energia.

Por un lado tipo de metabolismo nos dice que estan "comiendo" las bacterias dentro del suelo y por ende que nichos ocupan en nuestro suelo. 

Por el otro lado fuente de energia nos dice la cantidad de autotrofos, heterotrofos y otros tipos de bacterias mas raras que forman parte de ciclos de nutrientes.

# Trabajando con los datos descargados

## Subir datos


# Flujo de trabajo en Metagenassist


```{r}

metabolismo <- read.csv("~/capR/curso/curso_Innovak/Material_clase/METABOLISM.filtered.csv")

energia <- read_csv("~/capR/curso/curso_Innovak/Material_clase/ENERGYSOURCE.filtered.csv")


```

## Preprocesamiento de datos

```{r}

# renombrar filas y quitar simple ID
row.names(metabolismo) <- metabolismo[,1] 
metabolismo <- metabolismo[,-1] # no correr dos veces 

#Siempre cambiar a matrix 
metabolismo <- data.matrix(t(metabolismo)) #transpose

# cambiar el orden 

metabolismo <- metabolismo[order(metabolismo[,1], decreasing = TRUE),] # parece que ya vienen en orden 

sorder <- c("S81", "S85", "S82", "S83")

metabolismo <- metabolismo[ , sorder]

#Cambiar nombres

row.names(metabolismo) <- c("Ammonia Oxidizer", "Sulfate Reducer",
                           "Dehalogenation","Nitrite Reducer",
                           "Sulfide Oxidizer", "Nitrogen Fixation",
                           "Xylan Degrader", "Chitin degradation",
                           "Chlorophenol degrading","Streptomycin Producer",
                           "Arom. Hydrocarb. Degrader", "Ligning degrader",
                           "Atrazine Metabolism", "Sulfur Oxidizer",
                           "Sulfur Metabolizer","Carbon Fixation",
                           "Stores Polyhydroxybutyrate",
                           "Gramicidin Producer", "Dinitrogen Fixing",
                           "Sulfur Reducer","Carbon Monoxide Oxidizer")


```

## Heatmap

```{r}
quantile_breaks <- function(xs, n = 10) {
  breaks <- quantile(xs, probs = seq(0,1, length.out = n))
  breaks[!duplicated(breaks)]
}

mat_breaks <- quantile_breaks(metabolismo, # la matriz
                              n = 21) 

pheatmap(metabolismo,
         cluster_rows = FALSE, cluster_cols = FALSE,
         scale = "none", #regresemos a que no nos ponga escala
         breaks = mat_breaks,
         color = colorRampPalette(c("seashell", "steelblue2","orchid4", "darkblue"))(19),
         gaps_Col = c(2),
         fontsize = 12)

```

```{r}

# poner los grupos como columnas

metab_stats <- t(metabolismo)

#unir metadatos

metadata <- data.frame(Tratamiento = c("Bioestimulante", "Bioestimulante", "Control","Control"), Suelo = c("Salino", "Salino", "No salino", "No salino")) # los cambiamos de orden basados en el objeto sorder para que nuetras muestras y metadatos coincidan


metab_stats <- cbind(metadata, metab_stats)


## Checamos normalidad

for(i in 3:ncol(metab_stats)){
  shapiro <- shapiro.test(metab_stats[,i])
  normal <- ifelse(shapiro[["p.value"]]>0.05, "YES", "NO")
  print(c(i, normal))
}

### For loop T. test ###

# Paso 1: Tabla vacia (siempre especifica para sus datos)

phyla_pvalues <- data.frame(Tratamiento = rep(NA,21),
                            Suelo= rep(NA,21))


for(i in 3:ncol(metab_stats)){
  T_trat <- t.test(metab_stats[,i] ~ Tratamiento, data = metab_stats)
  S_trat <- t.test(metab_stats[,i] ~ Suelo, data = metab_stats)
  j <- i-2
  phyla_pvalues$Tratamiento[j] <- T_trat[["p.value"]]
  phyla_pvalues$Suelo[j] <- S_trat[["p.value"]]
}

# Nombrar las columnas
row.names(phyla_pvalues) <- colnames(metab_stats[3:23]) 

# Pueden guardar esta tabla

write.csv(phyla_pvalues, "~/capR/curso/curso_Innovak/Material_clase/vidmetab_pvalues.csv")
```

# Ejercicio 
realizar el analisis estadistico on fuente de energia

# conclusiones funcionales

Se puede conetar con analisis taxonomico?


